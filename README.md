# Gaussian Mechanism as Protection from Sensitive Input Memorization

I have now written a paper on theoretical differential privacy; see [here](https://www.prestonfu.com/files/DP_PIN_Protection.pdf). The [PIN protection case study](src/pin_protect.ipynb) is described in ยง5.

**Abstract:** We study the mathematical notion of differential privacy and its quantitative properties and qualitative attributes in real-world usage. In particular, we investigate the differentially private mechanisms
of randomized response and the Laplace mechanism. Our discussion concludes with a case study on
protecting PIN numbers from a perplexity-based attack on an input-memorizing LSTM model through
Gaussian noise sampling.

This project was completed at Inspirit AI, December 2021. The paper was written independently.